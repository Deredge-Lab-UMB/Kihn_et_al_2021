###
Script used to iteratively cluster trajectories, used after HDXer reweighing, with the given topology and trajectory files, along with the weights file generated by the find_weighted_frames.py script. TICA clustering is defaulted to backbone dihedral angles with a frame to frame RMSD cutoff of 3Ã… or a cluster containing less than 1001 frames. See details in  Kihn et. al., 2021
###




#!/usr/bin/env python
import pandas as pd
import os
import numpy as np
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
import glob
import kneed #name for kneedle algorithm
from kneed import KneeLocator
import scipy
import mdtraj as md
from tkinter.filedialog import askopenfilename
import tkinter.simpledialog
import matplotlib
#matplotlib.use('TkAgg')
import pyemma
import mdtraj as md
from pyemma.util.contexts import settings
from timeit import default_timer as timer
# Automatic TICA, and K-means clustering script


plt.rcParams["font.weight"] = "bold"
plt.rcParams["axes.labelweight"] = "bold"
plt.rcParams['font.size'] = 10
plt.rcParams['axes.labelsize'] = 10
plt.rcParams['axes.titlesize'] = 10
plt.rcParams['xtick.labelsize'] = 8
plt.rcParams['ytick.labelsize'] = 8
plt.rcParams['legend.fontsize'] = 10
plt.rcParams['figure.titlesize'] = 12

class Frame():
   def __init__(self,*args):
       ...

def load_inputs():  # gets user input for orginal reweighting files for iterative clustering
    weights_file = '/home/dderedge/Desktop/DXPS_Clustering/Weights_labeled_DXPS_w_Map_Chain_1.csv'
    traj_file = '/home/dderedge/Desktop/DXPS_Clustering/DXPS_Anton_Full_Traj.dcd'
    top_file = '/home/dderedge/Desktop/DXPS_Clustering/stripped.pdb'
    save_loc = '/home/dderedge/Desktop/DXPS_Clustering/'
    print("Saving results in: " + str(save_loc))
    return save_loc, weights_file, traj_file, top_file

def tica_run(top_1, traj_1, save_loc):    # runs pyemma tica and outputs tica plot and corresponding xy coordinates for each frame          
    feat = pyemma.coordinates.featurizer(top_1)
    feat.add_backbone_torsions(periodic=False) # sets collective variable for tica analysis
    data = pyemma.coordinates.load(traj_1, features=feat) 
    tica = pyemma.coordinates.tica(data, dim=3, lag=5)
    tica_concatenated = np.concatenate(tica.get_output())
    fig, axes = plt.subplots(1, 3, figsize=(12, 3), sharex=True)
    pyemma.plots.plot_feature_histograms(
        tica_concatenated, ['tica {}'.format(i + 1) for i in range(tica.dimension())], ax=axes[0])
    pyemma.plots.plot_density(*tica_concatenated[:, :2].T, ax=axes[1], cbar=False, logscale=True)
    pyemma.plots.plot_free_energy(*tica_concatenated[:, :2].T, ax=axes[2], legacy=False)
    for ax in axes.flat[1:]:
        ax.set_xlabel('tica 1')
        ax.set_ylabel('tica 2')
    fig.tight_layout()
    np.savetxt(save_loc + 'Tica_output.txt', tica_concatenated[:, :2])
    plt.savefig(save_loc + 'TICA.png',dpi=600)

def load_tica(save_loc): # loads tica xy coordinates
    tica_file = save_loc + 'Tica_output.txt'
    return tica_file

def kmeans_run(first_round, tica, save, weights_1, traj_1, top_1, counter, name_list, name, RMSD_cutoff): # peforms initial kmeans analysis
     print('kmeans first round:' +  str(first_round))
     start = timer()  
     df = load_data(tica) # processes tica output file 
     end = timer()
     print('load_data: ' + str(end-start))
     start = timer()  
     frames = create_frames(df) # creates frame objects and assigns xy values to the frames
     end = timer()
     print('create_frames: ' + str(end-start))
     start = timer()  
     WCSS, knee = number_kmeans(df,save)  # find the ideal number of clusters form the kmeans, makes L-curve kneedle uses
     end = timer()
     print('number_kmeans: ' + str(end-start))
     #clusters_named = 0 # keeps track of stages named
     if knee > 1:
         start = timer()  
         centers = find_centroid(df, knee, save) # find the centroid coordinates for the ideal number of kmeans
         end = timer()
         print('find_centroid: ' + str(end-start))
         start = timer()  
         sort_frames(frames, centers) # assigns clusters to frames
         end = timer()
         print('sort_frames: ' + str(end-start))
         start = timer()  
         frames = find_outliers(frames,centers) # finds outliers relative to the kmeans centroids
         end = timer()
         print('find_outliers: ' + str(end-start))
         start = timer()  
         check_clustering(frames,centers,save)
         end = timer()
         print('check_clustering: ' + str(end-start))
         start = timer()  
         frames = weights(frames, weights_1)
         end = timer()
         print('weights: ' + str(end-start))
         top = md.load_topology(top_1)
         print('Topology Loaded')
         traj = md.load( traj_1, top=top)
         traj_length = traj.n_frames
         print(traj_length)
         print('Trajectory Loaded')
         rmsds = md.rmsd(traj, traj, 0) 
         avg = np.average(rmsds) 
         print("Average frame to frame RMSD: " + str(avg))
         start = timer()  
         output_clusters(frames, traj, save, first_round, name)
         end = timer()
         print('output_clusters: ' + str(end-start))
         for i in range(int(knee)):
             if first_round == True:
                 traj_df = pd.read_csv(save + "Cluster_Results.txt")
                 if int(traj_df.at[i,"Length"]) >= 1000 and avg >= RMSD_cutoff:# this means the cluster needs to be clustered again average rmsd cutoff set to 3
                     name = str(i+1)
                     print('KMEANS RUNS AGAIN! I = ' + str(i+1))
                     if name not in (name_list):
                         name_list.append(str(i+1))
             if first_round == False:
                 traj_df = pd.read_csv(save + "Cluster_Results.txt")
                 if int(traj_df.at[i,"Length"]) >= 1000 and avg >= RMSD_cutoff:# this means the cluster needs to be clustered again average rmsd cutoff set to 3
                     print(traj_length)	 
                     print('KMEANS RUNS AGAIN!  I = ' + str(i+1))
                     parent = name_list[counter]
                     print(str(parent))
                     name = str(parent) + "_" + str(i+1)
                     if name not in (name_list):
                         name_list.append(name) 
                 #clusters_named =  clusters_named + 1
     if first_round == False:
         counter = counter + 1
     if knee <= 1:
         print('No additional clusters found')
     return (name_list, counter)

def load_data(file_path): #processes tica output file 
    df = pd.read_csv(file_path, header=None, sep='\s+') 
    columns = ['X','Y']
    df.columns = columns
    return df

def create_frames(df): # creates frame objects and assigns xy values to the frames
    frame_list = [] 
    x = 0
    for r in df.iterrows(): 
        f = Frame()
        setattr(f,'number',x)
        setattr(f,'X',float(df.at[x,'X']))
        setattr(f,'Y',float(df.at[x,'Y']))
        frame_list.append(f)
        x = x+1 
    return(frame_list)


def number_kmeans(df, save_loc): # find the ideal number of clusters form the kmeans, makes L-curve kneedle uses
    WCSS = []
    k_data_x = df[['X']].values
    k_data_y = df[['Y']].values
    k_data = np.column_stack((k_data_x, k_data_y))
    for i in range(1,16):
        model = KMeans(n_clusters = i,init = 'k-means++')
        model.fit(k_data)
        WCSS.append(model.inertia_)
    fig = plt.figure(figsize = (7,7))
    plt.plot(range(1,16),WCSS, linewidth=4, markersize=12,marker='o',color = 'red')
    plt.xticks(np.arange(16))
    plt.xlabel("Number of clusters")
    plt.ylabel("WCSS")
    kneed_x = range(1,16)
    kneed_y = WCSS
    df = pd.DataFrame(columns=['Cluster_Number','WCSS'])
    i = 0
    for num in kneed_x:
        df.at[i,'Cluster_Number'] = num
        df.at[i, 'WCSS'] = kneed_y[i]
        i = i + 1 
    kmeans_graph = KneeLocator(kneed_x, kneed_y, S=1.0, curve="convex", direction="decreasing", interp_method="interp1d") #KneeLocator(x values, y values, sensitivity = , curve = '', direction of curve = '', interp_method='interp1d' or 'polynomial' )
    knee_x = kmeans_graph.knee
    knee_y = kmeans_graph.knee_y
    z = df.loc[(df['Cluster_Number'] == knee_x) & (df['WCSS'] == knee_y)]
    ztext = (z['Cluster_Number'].to_string(index=False))
    xtext = round(kmeans_graph.knee, 3)
    ytext = round(kmeans_graph.knee_y, 3)
    gvalue = ("Cluster = " + str(ztext) + " at WCSS = " + str(ytext))
	#Specification of the plot styles, lables, and size.
    plt.style.use("classic")
    plt.figure(figsize=(8, 6))
    plt.title(" Normalized and Difference K Means Clustering Graph")
    plt.xlabel('Cluster_Number')
    plt.ylabel('WCSS')
    plt.plot(kmeans_graph.x_normalized, kmeans_graph.y_normalized, '-o', linewidth=2.5, label="Normalized")
    plt.plot(kmeans_graph.x_difference, kmeans_graph.y_difference, '-o', linewidth=2.5, label="Difference")
    colors = ["r", "g"]
    for k,c,o in zip(
        [kmeans_graph.norm_knee], ["black"], ["Knee"]):
        plt.vlines(k, 0, max(kmeans_graph.y_normalized), linestyles="--", colors=c, linewidth=2, label=o)
        plt.legend()
    plt.savefig(str(save_loc) + 'Kmeans_Norm-Diff.png')
    plt.close()
    plt.style.use("classic")
    plt.figure(figsize=(8, 6))
    plt.title( "Kmeans Graph")
    plt.xlabel('Cluster_Number')
    plt.ylabel('WCSS')
    plt.plot(kmeans_graph.x, kmeans_graph.y,'-o', linewidth=2.5)
    plt.annotate([gvalue], (knee_x, knee_y))
    plt.xlim([kmeans_graph.x[0],kmeans_graph.x[-1]])
    colors = ["r"]
    for n,t,p in zip(
        [knee_x], ["black"], ["Knee"]):
        plt.vlines(n, 0, max(kmeans_graph.y), linestyles="--", colors=t, linewidth=2, label=p)
        plt.legend()
    plt.savefig(str(save_loc)  + '_kmeans.png')
    fig.savefig(str(save_loc) + 'K_means_cluster_number.png', dpi=600)
    plt.close()
    estimator = KMeans(n_clusters=3)
    estimator.fit(k_data)
    estimator.labels_
    {i: np.where(estimator.labels_ == i)[0] for i in range(estimator.n_clusters)} 
    return (WCSS,knee_x)  # knee_x is the found number of kmeans  

def find_centroid(df,knee, save_loc): # find the centroid coordinates for the ideal number of kmeans
    k_data_x = df[['X']].values
    k_data_y = df[['Y']].values
    k_data = np.column_stack((k_data_x, k_data_y))
    model = KMeans(n_clusters = knee, init = "k-means++", max_iter = 300, n_init = 10, random_state =0)
    cluster = model.fit(k_data)
    centroids = cluster.cluster_centers_
    with open(str(save_loc) + 'centroid_values.txt', 'w+') as f:
        f.write('X, Y' + '\n')
        for num in centroids:
            f.write(str(num)+'\n')
        f.close()         
    return(centroids)
	
def sort_frames(frames, centers): # assigns clusters to frames
    x = 0
    for f in frames:
        setattr(f,'cluster',0)
        setattr(f,'distance',0)
        i = 0
        for c in centers:
            d =  ((((f.X-c[0])**2) + ((f.Y-c[-1])**2) )**0.5)
            if d <= f.distance and f.distance != 0:
                setattr(f,'distance',d)
                setattr(f,'cluster',i+1)
            if f.distance == 0:
                setattr(f,'distance',d)
                setattr(f,'cluster',i+1)
            i = i + 1 
        x = x+1 

def find_outliers(frames,centers): # finds outliers relative to the kmeans centroids
    i = 0
    output_list = []
    for c in centers:
        f_list = []
        d_list = []
        for f in frames:
            if f.cluster == i+1:
                f_list.append(f)   
        for d in f_list:
            d_list.append(d.distance)
        Q_3,Q_1 = np.percentile(d_list, [75,25])
        iqr = Q_3 - Q_1
        uf = Q_3 + (1.5*(iqr))
        lf = Q_1 - (1.5*(iqr))
        i = i + 1
        for d in f_list:
            if d.distance <= uf or d.distance >= lf:
                output_list.append(d)
            else: 
                print('outlier identified')    
    return(output_list)

def check_clustering(frames, knee,save_loc): #recreates tica plot with points colored by kmeans centroid
    plt.figure(figsize=(8, 6))
    i = 0
    color = ['deeppink','red','dodgerblue','yellow','darkblue','seagreen','aquamarine','darkred','slategrey','palegreen','crimson','mediumslateblue','blueviolet','magenta','teal', 'salmon']
    for k in knee:    
        x = []
        y = []
        for f in frames:
            if f.cluster == i+1:
                x.append(f.X)
                y.append(f.Y)
        plt.scatter(x, y, c=color[i])
        i = i + 1
    plt.savefig(str(save_loc) + 'Kmeans_results.png')
    plt.close()

def weights(frames, file_path): # reads in the weights from reweighting
     wts = pd.read_csv(file_path)
     for f in frames:
         i = 0 
         for row in wts.iterrows():
             if f.number == int(wts.at[i,'Frame']):
                 setattr(f,'weight',wts.at[i,'Weight'])
                 wts.drop(i,axis=0,inplace=True)
                 wts = wts.reset_index(drop=True)
                 break
             i = i + 1
     return frames

def output_clusters(frames, traj, save_loc, first_round, name): # creates the output trajectories and weights files
    i =0
    frames.sort(key=lambda x: x.cluster)
    last_cluster = 1
    first_frame = True
    c_traj = []
    weights = []
    frame = []
    with open(str(save_loc) + 'Cluster_Results.txt', "w+") as d:
        d.write('Cluster,Length' + '\n')
        for f in frames:
            if f.cluster == last_cluster:
                if first_frame == False:
                    c_traj = c_traj.join(traj[f.number])  
                if first_frame == True:
                    c_traj = traj[f.number]
                    first_frame = False 
                weights.append(f.weight)
                frame.append(f.number)
            if first_round == True:
               if f.cluster != last_cluster or i == len(frames)-1:
                   c_traj.save_dcd(str(save_loc) + 'Cluster_' + str(last_cluster) + '.dcd')
                   d.write(str(last_cluster) +','+ str(len(weights)) + '\n')
                   with open(str(save_loc) + 'Cluster_' + str(last_cluster) + '_Iterative_Clustering_Input.txt', 'w+') as h:
                       h.write('Weight,Frame' + '\n')
                       z = 0
                       for w in weights:
                           h.write(str(weights[z]) + ',' + str(z) + '\n')
                           z = z + 1 
                       h.close()
                   print('Cluster ' + str(last_cluster) + ' of length ' + str(len(weights)) + ' frames is written')
                   c_traj = traj[f.number]
                   last_cluster = f.cluster 
                   weights = [f.weight]
            if first_round == False:
                if f.cluster != last_cluster or i == len(frames)-1:
                    c_traj.save_dcd(str(save_loc) + 'Cluster_' + str(name) + '_' + str(last_cluster) + '.dcd')
                    d.write(str(last_cluster) +','+ str(len(weights)) + '\n')
                    with open(str(save_loc) + 'Cluster_' + str(name) + '_' + str(last_cluster) + '_Iterative_Clustering_Input.txt', 'w+') as h:
                        h.write('Weight,Frame' + '\n')
                        z = 0
                        for w in weights:
                            h.write(str(weights[z]) + ',' + str(z) + '\n')
                            z = z + 1 
                        h.close()
                    print('Cluster ' + str(name) + '_' + str(last_cluster) + ' of length ' + str(len(weights)) + ' frames is written')
                    c_traj = traj[f.number]
                    last_cluster = f.cluster 
                    weights = [f.weight]
            i = i + 1
        d.close()

def get_name (name_list, counter):
    name = str(name_list[counter])
    print('my name is: ' + name)
    return name

def get_save (save, name):
    n = 0
    save_new = ''
    new_folder = (str(save) + 'Cluster_' + str(name)) 
    save_new = save + 'Cluster_' + str(name) + '/' 
    try:
        os.makedirs(new_folder)
    except:
        pass
    return save_new

def get_inputs(save, name):
    n = 0
    kyle = ''
    number_count = ((len(name)-1)/2) + 1 
    if int(number_count) == 1: 
        weights_file = save + 'Cluster_'+ str(name[n]) + '_Iterative_Clustering_Input.txt'
        traj_file = save + 'Cluster_'+ str(name[n]) +'.dcd'
    if int(number_count) != 1: 
        for f in range(len(name)-2):
           kyle = kyle + str(name[f])
        weights_file = str(save) + 'Cluster_' + str(kyle) + '/Cluster_' + str(name) + '_Iterative_Clustering_Input.txt'
        traj_file = str(save) + 'Cluster_' + str(kyle) + '/Cluster_' + str(name) + '.dcd'
    start = timer()  
    save_loc = get_save(save, name)
    end = timer()
    print('get_save: ' + str(end-start))
    return save_loc, weights_file, traj_file




first_round = True
name_list = []
first_name = ''
print("Inital name list " + str(name_list))
counter = 0 # will iterate after every round and never reset, to keep track of position in name_list which the position tells which clusters have and have not been clustered


RMSD_cutoff = 0.1 # Set the RMSD cutoff for clustering in angstroms.
save, weights_1, traj_1, top_1 = load_inputs() # gets user input for orginal reweighting files for iterative clustering
start = timer()
tica_run(top_1, traj_1, save)  # runs pyemma tica and outputs tica plot and corresponding xy coordinates for each frame
end = timer()
print('tica_run: ' + str(end-start))
start = timer()           
tica = load_tica(save) # loads tica xy coordinates
end = timer()
print('load_tica: ' + str(end-start))
start = timer()  
name_list, counter = kmeans_run(first_round, tica, save, weights_1, traj_1, top_1, counter, name_list, first_name, RMSD_cutoff) # peforms initial kmeans analysis
end = timer()
print('kmeans_run: ' + str(end-start))
print("First Clustering name list " + str(name_list))
first_round = False
print(str(first_round))
i = 1
for b in name_list: 
    print(" Clustering name list " + str(i) + ' ' + str(name_list))
    start = timer()  
    name = get_name(name_list, counter) # calculate name
    end = timer()
    print('get_name: ' + str(end-start))
    start = timer()  
    save_loc, weights_1, traj_1 = get_inputs(save, name)
    end = timer()
    print('get_inputs: ' + str(end-start))
    start = timer()  
    tica_run(top_1, traj_1, save_loc) #run tica on calculated inputs
    end = timer()
    print('tica_run: ' + str(end-start)) 
    start = timer()  
    tica = load_tica(save_loc) # save tica
    end = timer()
    print('load_tica: ' + str(end-start))
    start = timer()  
    name_list, counter = kmeans_run(first_round, tica, save_loc, weights_1, traj_1, top_1, counter, name_list, name, RMSD_cutoff) # run kmeans
    end = timer()
    print('kmeans_run: ' + str(end-start))
    i = i + 1
print('I have finished clustering, BYE!')         
